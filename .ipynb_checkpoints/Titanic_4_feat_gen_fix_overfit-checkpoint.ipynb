{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = r'C:\\Users\\lu.jin01\\OneDrive - Cardinal Health\\2.Jpt_code\\Geron2\\datasets\\titanic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas display options to show full table\n",
    "def set_pandas_display_options() -> None:\n",
    "    display = pd.options.display\n",
    "\n",
    "    display.max_columns = 1000\n",
    "    display.max_rows = 1000\n",
    "    display.max_colwidth = 199\n",
    "    display.width = None\n",
    "    # display.precision = 2  # set as needed\n",
    "\n",
    "set_pandas_display_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11) (418, 10)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train = pd.read_csv(os.path.join(f,'train.csv'), index_col='PassengerId')\n",
    "    test = pd.read_csv(os.path.join(f,'test.csv'), index_col='PassengerId')\n",
    "except:\n",
    "    train = pd.read_csv(os.path.join('data','train.csv'), index_col='PassengerId')\n",
    "    test = pd.read_csv(os.path.join('data','test.csv'), index_col='PassengerId')\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cols having missing values: *Age, cabin, and Embarked***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if classes are evenly distributed\n",
    "train.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Glynn, Miss. Mary Agatha</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335677</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mamee, Mr. Hanna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2677</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kraeff, Mr. Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349253</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rogers, Mr. William John</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.C./A.4. 23567</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lennon, Mr. Denis</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>370371</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                           Name     Sex  Age  \\\n",
       "PassengerId                                                                 \n",
       "6                   0       3               Moran, Mr. James    male  NaN   \n",
       "20                  1       3        Masselmani, Mrs. Fatima  female  NaN   \n",
       "27                  0       3        Emir, Mr. Farred Chehab    male  NaN   \n",
       "29                  1       3  O'Dwyer, Miss. Ellen \"Nellie\"  female  NaN   \n",
       "30                  0       3            Todoroff, Mr. Lalio    male  NaN   \n",
       "33                  1       3       Glynn, Miss. Mary Agatha  female  NaN   \n",
       "37                  1       3               Mamee, Mr. Hanna    male  NaN   \n",
       "43                  0       3            Kraeff, Mr. Theodor    male  NaN   \n",
       "46                  0       3       Rogers, Mr. William John    male  NaN   \n",
       "47                  0       3              Lennon, Mr. Denis    male  NaN   \n",
       "\n",
       "             SibSp  Parch           Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                         \n",
       "6                0      0           330877   8.4583   NaN        Q  \n",
       "20               0      0             2649   7.2250   NaN        C  \n",
       "27               0      0             2631   7.2250   NaN        C  \n",
       "29               0      0           330959   7.8792   NaN        Q  \n",
       "30               0      0           349216   7.8958   NaN        S  \n",
       "33               0      0           335677   7.7500   NaN        Q  \n",
       "37               0      0             2677   7.2292   NaN        C  \n",
       "43               0      0           349253   7.8958   NaN        C  \n",
       "46               0      0  S.C./A.4. 23567   8.0500   NaN        S  \n",
       "47               1      0           370371  15.5000   NaN        Q  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate age missing rows\n",
    "train[(train.Age.isna()) & (train.Pclass==3)].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: no evidence of missing age due to child-fare**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female  male\n",
       "Survived              \n",
       "0             81   468\n",
       "1            233   109"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.pivot_table('Name',columns='Sex',index='Survived',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Embarked</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>47</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>30</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Embarked   C   Q    S\n",
       "Survived             \n",
       "0         75  47  427\n",
       "1         93  30  217"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.pivot_table('Name',columns='Embarked',index='Survived',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore.Ticket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore.Ticket.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore[explore.Ticket.str.len()<7].sort_values(by='Ticket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Fare_int</th>\n",
       "      <th>0.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>20.0</th>\n",
       "      <th>30.0</th>\n",
       "      <th>40.0</th>\n",
       "      <th>50.0</th>\n",
       "      <th>60.0</th>\n",
       "      <th>70.0</th>\n",
       "      <th>80.0</th>\n",
       "      <th>90.0</th>\n",
       "      <th>110.0</th>\n",
       "      <th>120.0</th>\n",
       "      <th>130.0</th>\n",
       "      <th>140.0</th>\n",
       "      <th>150.0</th>\n",
       "      <th>160.0</th>\n",
       "      <th>210.0</th>\n",
       "      <th>220.0</th>\n",
       "      <th>230.0</th>\n",
       "      <th>250.0</th>\n",
       "      <th>260.0</th>\n",
       "      <th>510.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Fare_int  0.0    10.0   20.0   30.0   40.0   50.0   60.0   70.0   80.0   \\\n",
       "Survived                                                                  \n",
       "0          16.0  327.0   54.0   76.0   16.0   17.0    6.0   14.0    8.0   \n",
       "1           1.0  113.0   46.0   59.0   12.0   13.0   19.0    5.0   23.0   \n",
       "\n",
       "Fare_int  90.0   110.0  120.0  130.0  140.0  150.0  160.0  210.0  220.0  \\\n",
       "Survived                                                                  \n",
       "0           1.0    4.0    NaN    NaN    1.0    3.0    NaN    1.0    1.0   \n",
       "1          12.0    7.0    4.0    4.0    2.0    6.0    2.0    3.0    NaN   \n",
       "\n",
       "Fare_int  230.0  250.0  260.0  510.0  \n",
       "Survived                              \n",
       "0           1.0    1.0    2.0    NaN  \n",
       "1           3.0    1.0    4.0    3.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Fare_int'] = train.Fare.round(-1)\n",
    "test['Fare_int'] = test.Fare.round(-1)\n",
    "train.pivot_table('Name',columns='Fare_int',index='Survived',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.626179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.343690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age\n",
       "Survived           \n",
       "0         30.626179\n",
       "1         28.343690"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.pivot_table('Age',index='Survived',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Fare_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>33.01908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>49.25032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>510.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare  \\\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208   \n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429   \n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400   \n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200   \n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000   \n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   \n",
       "\n",
       "        Fare_int  \n",
       "count  891.00000  \n",
       "mean    33.01908  \n",
       "std     49.25032  \n",
       "min      0.00000  \n",
       "25%     10.00000  \n",
       "50%     10.00000  \n",
       "75%     30.00000  \n",
       "max    510.00000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.hist(bins=30,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**1. process name, sex, and age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine names\n",
    "noble = ['Duke.','Duchess.','Marquess.','Marchioness.','Lord.','Lady.','Earl.','Countess.','Honourable.',\n",
    "    'Viscount','Viscountess','Baron','Baroness','Knight.']\n",
    "Ms = ['Mrs.', 'Miss.']\n",
    "\n",
    "train['Noble'] = train['Name'].str.contains('|'.join(noble))\n",
    "test['Noble'] = test['Name'].str.contains('|'.join(noble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Noble</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>340</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Noble     False  True \n",
       "Survived              \n",
       "0           548      1\n",
       "1           340      2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.pivot_table('Name',columns='Noble',index='Survived',aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Noble not worth it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sex and age features\n",
    "bins = [0,16,60,120]\n",
    "group_names = ['Young','Adult','Senior']\n",
    "train.loc[:,'Age_Group'] = pd.cut(train.Age, bins, labels=group_names)\n",
    "train.loc[:,'Sex-Age'] = train['Sex'] + train['Age_Group'].astype(str)\n",
    "\n",
    "test.loc[:,'Age_Group'] = pd.cut(test.Age, bins, labels=group_names)\n",
    "test.loc[:,'Sex-Age'] = test['Sex'] + test['Age_Group'].astype(str)\n",
    "\n",
    "# disect Cabin feature\n",
    "train['Cabin1'] = train.Cabin.str[0]\n",
    "test['Cabin1'] = test.Cabin.str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **2. Mean encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train val split\n",
    "from sklearn.model_selection import train_test_split\n",
    "ttrain, tval = train_test_split(train, test_size = 0.2, random_state = 100)\n",
    "ttrain, tval = ttrain.copy(), tval.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.1 Cross Validation Regularizatoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age          145\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin        538\n",
       "Embarked       2\n",
       "Fare_int       0\n",
       "Noble          0\n",
       "Age_Group    145\n",
       "Sex-Age        0\n",
       "Cabin1       538\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttrain.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**only `Embarked` is fit for mean encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cv_mean_encode(df, col, label, n_splits=5, random_state=12, shuffle=True):\n",
    "    df[col+'_me_cv'] = 0\n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "    for train_index, val_index in kf.split(df): # use cross-val index to reduce encoding results' correlation with target\n",
    "        train, val = df.iloc[train_index], df.iloc[val_index]\n",
    "        mean = val[col].map(train.groupby(col)[label].mean())\n",
    "        df.iloc[val_index, train.columns.get_loc(col+'_me_cv')] = mean\n",
    "        df[col+'_me_cv'].fillna(train[label].mean(), inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 16), (712, 16))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, ttrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_feats = ['Embarked','Cabin1','Sex','Sex-Age']\n",
    "\n",
    "for col in me_feats:\n",
    "    cv_mean_encode(train, col, 'Survived')\n",
    "    cv_mean_encode(ttrain, col, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ##### mean Encode for val and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mean encoding for testing set using CV\n",
    "from sklearn import base\n",
    "\n",
    "class KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, train, orig_cols, enc_cols):\n",
    "        \n",
    "        self.train = train\n",
    "        self.orig_cols = orig_cols\n",
    "        self.enc_cols = enc_cols\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        assert(isinstance(self.orig_cols,list))\n",
    "        assert(isinstance(self.enc_cols,list))\n",
    "        enc_cols_lis = []\n",
    "        for orig_col, enc_col in zip(self.orig_cols, self.enc_cols):\n",
    "            mean =  self.train.groupby(orig_col)[enc_col].mean() # the label mean of train set\n",
    "            X[enc_col] = X[orig_col].map(mean)\n",
    "        enc_cols_lis.append(X)\n",
    "        \n",
    "        return pd.concat(enc_cols_lis, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "me_feats_transformed = [feat + '_me_cv' for feat in me_feats]\n",
    "\n",
    "# mean encode val set with ttrain data\n",
    "test_encoder = KFoldTargetEncoderTest(ttrain, me_feats, me_feats_transformed)\n",
    "tval = test_encoder.fit_transform(tval)\n",
    "\n",
    "# mean encode test set with entire train data\n",
    "test_encoder = KFoldTargetEncoderTest(train, me_feats, me_feats_transformed)\n",
    "test = test_encoder.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3. KNN encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors # Unsupervised learner for implementing neighbor searches\n",
    "\n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "        This class should implement KNN features extraction,\n",
    "        The to-be-fitted data cannot contail null values, and must be normalized\n",
    "    '''\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list # list of K_neighbors candidates, e.g.: [2,3,4,5,...]\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list) \n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps        \n",
    "        self.n_classes_ = n_classes\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "            Set up the train set and self.NN object\n",
    "        '''\n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
    "                                      metric=self.metric, \n",
    "                                      n_jobs=1, \n",
    "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "        \n",
    "        # Store labels \n",
    "        self.y_train = y\n",
    "        \n",
    "        # Save how many target classes we have\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
    "        \n",
    "        \n",
    "    def predict(self, X):       \n",
    "        '''\n",
    "            Produces KNN features for every instance of X\n",
    "        '''\n",
    "        test_feats = []\n",
    "        \n",
    "        if self.n_jobs == 1:\n",
    "            cols = self.get_features_for_one(X[:1])[1]\n",
    "            for i in range(X.shape[0]): # iterate through all instances\n",
    "                test_feats.append(self.get_features_for_one(X[i:i+1])[0])\n",
    "                \n",
    "        else:\n",
    "            from multiprocessing import Pool\n",
    "            import os\n",
    "            if __name__ == '__main__':\n",
    "                with Pool(processes=self.n_jobs) as pool:\n",
    "                    # evaluate \"f(X)\" asynchronously\n",
    "                    res = pool.apply_async(self.get_features_for_one, X.shape[0])      # runs in *only* one process\n",
    "                    print(res.get(timeout=1))             # prints \"400\"\n",
    "\n",
    "                    # evaluate \"os.getpid()\" asynchronously\n",
    "                    res = pool.apply_async(os.getpid, ()) # runs in *only* one process\n",
    "                    print(res.get(timeout=1))             # prints the PID of that process\n",
    "\n",
    "                    # launching multiple evaluations asynchronously *may* use more processes\n",
    "                    multiple_results = [pool.apply_async(os.getpid, ()) for i in range(self.n_jobs)]\n",
    "                    print([res.get(timeout=1) for res in multiple_results])\n",
    "\n",
    "                    # make a single worker sleep for 10 secs\n",
    "                    res = pool.apply_async(time.sleep, (10,))\n",
    "                    try:\n",
    "                        print(res.get(timeout=1))\n",
    "                        results = [pool.apply(self.get_features_for_one, args=(X[i:i+1],))[0] for i in range(X.shape[0])]\n",
    "                        test_feats.append(results)\n",
    "                    except TimeoutError:\n",
    "                        print(\"We lacked patience and got a multiprocessing.TimeoutError\")\n",
    "                    \n",
    "            \n",
    "        return pd.DataFrame(np.vstack(test_feats), columns = cols)\n",
    "        \n",
    "        \n",
    "    def get_features_for_one(self, x):\n",
    "        '''\n",
    "            Computes KNN features for a single instance `x`\n",
    "        '''\n",
    "\n",
    "        NN_output = self.NN.kneighbors(x)\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores indices of the neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores distances to corresponding neighbors\n",
    "        neighs_dist = NN_output[0][0] \n",
    "\n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores labels of corresponding neighbors\n",
    "        \n",
    "        # stores the labels of corresponding neighbors\n",
    "        neighs_y = np.array(self.y_train)[neighs]\n",
    "#         import pdb; pdb.set_trace()\n",
    "    \n",
    "        # Eventually it will be a list of lists or np.arrays\n",
    "        # and we will use np.hstack to concatenate those\n",
    "        return_list = [] \n",
    "        colname_list = []\n",
    "        \n",
    "        \n",
    "        ''' \n",
    "            1. Fraction of instances of every class.\n",
    "               It is basically a KNNlassifiers predictions.\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            # YOUR CODE GOES HERE\n",
    "            label_counts = np.bincount(neighs_y[:k], minlength=self.n_classes) # e.g. 5_neighs, 3 are label_0, 2 are label_1 \n",
    "            feats = label_counts/label_counts.sum()\n",
    "            \n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "            for c in range(self.n_classes):\n",
    "                colname = str(k) + 'NN_Class' + str(c)\n",
    "                colname_list.append(colname)\n",
    "                \n",
    "        \n",
    "        '''\n",
    "            2. Same label streak: the largest number N, \n",
    "               such that N nearest neighbors have the same label.\n",
    "        '''\n",
    "        feats =  np.where(np.unique(neighs_y).size==1, neighs_y.size, np.argmin(np.array(neighs_y[:-1]==neighs_y[1:])) + 1)\n",
    " \n",
    "        assert feats.size == 1\n",
    "        return_list += [feats]\n",
    "        colname_list.append('Same_Label_Streak')\n",
    "        \n",
    "        \n",
    "        '''\n",
    "            3. Distances to closest instance of each class\n",
    "               Find the first instance of each class and take its distance as features.\n",
    "               \n",
    "               Distance = 999 if no neighboring instance of the some class, \n",
    "        '''\n",
    "#         feats = []\n",
    "#         for c in range(self.n_classes):\n",
    "#             dis_array = neighs_dist[np.where(neighs_y==c)]\n",
    "#             dis = 999 if dis_array.size==0 else dis_array[0] \n",
    "#             feats.append(dis)\n",
    "#             colname = 'Class' + str(c) + '_Min_Dist'\n",
    "#             colname_list.append(colname)\n",
    "            \n",
    "#         assert len(feats) == self.n_classes\n",
    "#         return_list += [feats]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "            4. Minimum *normalized* distance to objects of each class\n",
    "               As 3. but we normalize (divide) the distances\n",
    "               by the distance to the closest neighbor.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "        '''\n",
    "        feats = []\n",
    "        for c in range(self.n_classes):\n",
    "            dis_array = neighs_dist[np.where(neighs_y==c)]\n",
    "            dis = 999 if dis_array.size==0 else dis_array[0] / (neighs_dist[0] + self.eps)\n",
    "            feats.append(dis)\n",
    "            colname = 'Norm_Class' + str(c) + '_Min_Dist'\n",
    "            colname_list.append(colname)\n",
    "            \n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "    \n",
    "        '''\n",
    "            5. \n",
    "               5.1 Distance to Kth neighbor\n",
    "                   Think of this as of quantiles of a distribution\n",
    "               5.2 Distance to Kth neighbor normalized by \n",
    "                   distance to the first neighbor\n",
    "\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            feat_51 = neighs_dist[k-1]\n",
    "            colname_51 = 'Dist_to_Neighbor_' + str(k)\n",
    "            feat_52 = neighs_dist[k-1] / (neighs_dist[0] + self.eps) # YOUR CODE GOES HERE\n",
    "            colname_52 = 'Norm_Dist_to_Neighbor_' + str(k)\n",
    "            \n",
    "            return_list += [[feat_51, feat_52]]\n",
    "            colname_list += [colname_51, colname_52]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "            6. Mean distance to neighbors of each class for each K from `k_list` \n",
    "               For each class select the neighbors of that class among K nearest neighbors \n",
    "               and compute the average distance to those instances\n",
    "                   \n",
    "               If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            mean_dist = np.bincount(neighs_y[:k], weights=neighs_dist[:k], minlength=self.n_classes) \\\n",
    "                    / (np.bincount(neighs_y[:k], minlength=self.n_classes) + self.eps)\n",
    "            feats = np.where(mean_dist==0, 999, mean_dist)\n",
    "            \n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "            \n",
    "            for c in range(self.n_classes):\n",
    "                colname = str(k) + 'NN_Class' + str(c) + '_Mean_Dist'\n",
    "                colname_list.append(colname)\n",
    "        \n",
    "        # merge\n",
    "        knn_feats = np.hstack(return_list)\n",
    "\n",
    "#         return pd.DataFrame(knn_feats, columns = colname_list.tolist())\n",
    "        return knn_feats, colname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = ttrain.drop('Survived',axis=1), ttrain['Survived']\n",
    "knn_cols = ['SibSp','Parch','Fare','Sex-Age_me_cv','Embarked_me_cv'] # non-null numeric value\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_nnf = scaler.fit_transform(X_train[knn_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of our KNN feature extractor\n",
    "NNF = NearestNeighborsFeats(n_jobs=1, k_list=[5,7,9], metric='minkowski')\n",
    "\n",
    "# Fit on train set\n",
    "NNF.fit(X_train_nnf, y_train)\n",
    "\n",
    "# Get features for test\n",
    "X_train_knn_feats = NNF.predict(X_train_nnf)\n",
    "X_train_knn_feats.set_index(X_train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> get the KNN features for val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp             0\n",
       "Parch             0\n",
       "Fare              0\n",
       "Sex-Age_me_cv     0\n",
       "Embarked_me_cv    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, y_val = tval.drop('Survived',axis=1), tval['Survived']\n",
    "X_val_nnf = X_val[knn_cols]\n",
    "X_val_nnf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179, 5), (179, 5), (179, 21))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_nnf_scaled = scaler.transform(X_val_nnf)\n",
    "X_val_nnf_final = NNF.predict(X_val_nnf_scaled)\n",
    "X_val_nnf_final.set_index(X_val_nnf.index, inplace=True)\n",
    "X_val_nnf.shape, X_val_nnf_scaled.shape, X_val_nnf_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp             0\n",
       "Parch             0\n",
       "Fare              1\n",
       "Sex-Age_me_cv     0\n",
       "Embarked_me_cv    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_nnf = test[knn_cols]\n",
    "X_test_nnf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((418, 5), (418, 5), (418, 21))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deal with null value\n",
    "X_test_nnf_nonull = X_test_nnf.fillna(method='ffill',axis=1)\n",
    "\n",
    "X_test_nnf_scaled = scaler.transform(X_test_nnf_nonull)\n",
    "X_test_nnf_final = NNF.predict(X_test_nnf_scaled)\n",
    "X_test_nnf_final.set_index(X_test_nnf.index, inplace=True)\n",
    "X_test_nnf.shape, X_test_nnf_scaled.shape, X_test_nnf_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. select features for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 29), (179, 29), (418, 29))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cols_keep = ['Pclass','Age','SibSp','Parch','Fare','Embarked_me_cv','Cabin1_me_cv','Sex_me_cv']\n",
    "X_train_1 = X_train[X_cols_keep]\n",
    "X_val_1 = X_val[X_cols_keep]\n",
    "X_test_1 = test[X_cols_keep]\n",
    "\n",
    "X_train_final = pd.concat([X_train_1, X_train_knn_feats], axis=1)\n",
    "X_val_final = pd.concat([X_val_1, X_val_nnf_final], axis=1)\n",
    "X_test_final = pd.concat([X_test_1, X_test_nnf_final], axis=1)\n",
    "X_train_final.shape, X_val_final.shape, X_test_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training with GB Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xgb_clf = xgboost.XGBClassifier()\n",
    "# xgb_clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=4)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(xgb_clf.predict(X_val), y_val).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.21229\n",
      "Will train until validation_0-error hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-error:0.21229\n",
      "[2]\tvalidation_0-error:0.21229\n",
      "[3]\tvalidation_0-error:0.20112\n",
      "[4]\tvalidation_0-error:0.20112\n",
      "[5]\tvalidation_0-error:0.20112\n",
      "[6]\tvalidation_0-error:0.20112\n",
      "[7]\tvalidation_0-error:0.20112\n",
      "[8]\tvalidation_0-error:0.20112\n",
      "[9]\tvalidation_0-error:0.20112\n",
      "[10]\tvalidation_0-error:0.17318\n",
      "[11]\tvalidation_0-error:0.20112\n",
      "[12]\tvalidation_0-error:0.20112\n",
      "[13]\tvalidation_0-error:0.20112\n",
      "[14]\tvalidation_0-error:0.20670\n",
      "[15]\tvalidation_0-error:0.20670\n",
      "[16]\tvalidation_0-error:0.20670\n",
      "[17]\tvalidation_0-error:0.21229\n",
      "[18]\tvalidation_0-error:0.20670\n",
      "[19]\tvalidation_0-error:0.25140\n",
      "0.9691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5,\n",
       " 'learning_rate': 0.1310346110806326,\n",
       " 'max_depth': 4,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "xgb_params = {\n",
    "            'max_depth': [3,4,5],\n",
    "            'learning_rate':stats.reciprocal(0.005, 0.5),\n",
    "            'n_estimators':stats.randint(20, 230),\n",
    "            'gamma':[0, 0.5 ,1]\n",
    "         }\n",
    "\n",
    "random_tree = RandomizedSearchCV(xgb_clf, n_jobs=-1, param_distributions=xgb_params, \n",
    "                                 n_iter=300, cv=3, random_state=10)\n",
    "\n",
    "random_tree.fit(X_train_final, y_train, eval_set=[(X_val_final, y_val)], early_stopping_rounds=10)\n",
    "print(random_tree.best_score_.round(4))\n",
    "random_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_tree.best_estimator_.fit(X_train_final, y_train, eval_set=[(X_val_final, y_val)], early_stopping_rounds=10)\n",
    "y_val_hat = random_tree.best_estimator_.predict(X_val_final)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_val_hat, y_val).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Examine Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Examined mislabelled val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 29), (17, 29))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positive\n",
    "FP_idx = y_val[(y_val_hat == 1)&(y_val==0)].index\n",
    "FP = X_val_final.loc[FP_idx]\n",
    "# false negative\n",
    "FN_idx = y_val[(y_val_hat == 0)&(y_val==1)].index\n",
    "FN = X_val_final.loc[FN_idx]\n",
    "\n",
    "FP.shape, FN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_me_cv</th>\n",
       "      <th>Cabin1_me_cv</th>\n",
       "      <th>Sex_me_cv</th>\n",
       "      <th>5NN_Class0</th>\n",
       "      <th>5NN_Class1</th>\n",
       "      <th>7NN_Class0</th>\n",
       "      <th>7NN_Class1</th>\n",
       "      <th>9NN_Class0</th>\n",
       "      <th>9NN_Class1</th>\n",
       "      <th>Same_Label_Streak</th>\n",
       "      <th>Norm_Class0_Min_Dist</th>\n",
       "      <th>Norm_Class1_Min_Dist</th>\n",
       "      <th>Dist_to_Neighbor_5</th>\n",
       "      <th>Norm_Dist_to_Neighbor_5</th>\n",
       "      <th>Dist_to_Neighbor_7</th>\n",
       "      <th>Norm_Dist_to_Neighbor_7</th>\n",
       "      <th>Dist_to_Neighbor_9</th>\n",
       "      <th>Norm_Dist_to_Neighbor_9</th>\n",
       "      <th>5NN_Class0_Mean_Dist</th>\n",
       "      <th>5NN_Class1_Mean_Dist</th>\n",
       "      <th>7NN_Class0_Mean_Dist</th>\n",
       "      <th>7NN_Class1_Mean_Dist</th>\n",
       "      <th>9NN_Class0_Mean_Dist</th>\n",
       "      <th>9NN_Class1_Mean_Dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.571831</td>\n",
       "      <td>8.182631</td>\n",
       "      <td>0.856144</td>\n",
       "      <td>12.251021</td>\n",
       "      <td>0.938202</td>\n",
       "      <td>13.425234</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.325906</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.476230</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.575909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>0.734801</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.608924</td>\n",
       "      <td>2.516572</td>\n",
       "      <td>1.890405</td>\n",
       "      <td>2.675798</td>\n",
       "      <td>2.010013</td>\n",
       "      <td>2.895941</td>\n",
       "      <td>2.175380</td>\n",
       "      <td>1.750444</td>\n",
       "      <td>2.329213</td>\n",
       "      <td>1.750444</td>\n",
       "      <td>2.481582</td>\n",
       "      <td>2.026409</td>\n",
       "      <td>2.564454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.410277</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.112269</td>\n",
       "      <td>10.236291</td>\n",
       "      <td>0.151144</td>\n",
       "      <td>13.780823</td>\n",
       "      <td>0.171489</td>\n",
       "      <td>15.635731</td>\n",
       "      <td>0.076433</td>\n",
       "      <td>0.061618</td>\n",
       "      <td>0.099130</td>\n",
       "      <td>0.061618</td>\n",
       "      <td>0.118353</td>\n",
       "      <td>0.061618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8250</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.110619</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.157793</td>\n",
       "      <td>1.666515</td>\n",
       "      <td>0.165482</td>\n",
       "      <td>1.747722</td>\n",
       "      <td>0.217171</td>\n",
       "      <td>2.293628</td>\n",
       "      <td>0.131476</td>\n",
       "      <td>0.123961</td>\n",
       "      <td>0.148105</td>\n",
       "      <td>0.123961</td>\n",
       "      <td>0.170621</td>\n",
       "      <td>0.123961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.067631</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.288768</td>\n",
       "      <td>4.067631</td>\n",
       "      <td>0.416033</td>\n",
       "      <td>5.860297</td>\n",
       "      <td>0.812020</td>\n",
       "      <td>11.438222</td>\n",
       "      <td>0.288768</td>\n",
       "      <td>0.168231</td>\n",
       "      <td>0.288768</td>\n",
       "      <td>0.236508</td>\n",
       "      <td>0.288768</td>\n",
       "      <td>0.360062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.189989</td>\n",
       "      <td>0.106954</td>\n",
       "      <td>1.438413</td>\n",
       "      <td>0.135873</td>\n",
       "      <td>1.827339</td>\n",
       "      <td>0.234367</td>\n",
       "      <td>3.151968</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>0.099925</td>\n",
       "      <td>0.096725</td>\n",
       "      <td>0.107183</td>\n",
       "      <td>0.134107</td>\n",
       "      <td>0.107183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.356709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.003091</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.190531</td>\n",
       "      <td>2.034240</td>\n",
       "      <td>0.198737</td>\n",
       "      <td>2.121849</td>\n",
       "      <td>0.406510</td>\n",
       "      <td>4.340176</td>\n",
       "      <td>0.132497</td>\n",
       "      <td>0.145633</td>\n",
       "      <td>0.132497</td>\n",
       "      <td>0.166874</td>\n",
       "      <td>0.132497</td>\n",
       "      <td>0.205660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.531288</td>\n",
       "      <td>0.387003</td>\n",
       "      <td>1.828168</td>\n",
       "      <td>0.428944</td>\n",
       "      <td>2.026293</td>\n",
       "      <td>0.504325</td>\n",
       "      <td>2.382388</td>\n",
       "      <td>0.272547</td>\n",
       "      <td>0.345105</td>\n",
       "      <td>0.319658</td>\n",
       "      <td>0.366065</td>\n",
       "      <td>0.384879</td>\n",
       "      <td>0.366065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>11.585759</td>\n",
       "      <td>0.814757</td>\n",
       "      <td>12.006565</td>\n",
       "      <td>0.913874</td>\n",
       "      <td>13.467200</td>\n",
       "      <td>0.920443</td>\n",
       "      <td>13.564002</td>\n",
       "      <td>0.212158</td>\n",
       "      <td>0.800478</td>\n",
       "      <td>0.492228</td>\n",
       "      <td>0.800478</td>\n",
       "      <td>0.614557</td>\n",
       "      <td>0.800478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>7.295723</td>\n",
       "      <td>0.634462</td>\n",
       "      <td>7.639436</td>\n",
       "      <td>0.916857</td>\n",
       "      <td>11.039704</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>11.080384</td>\n",
       "      <td>0.142172</td>\n",
       "      <td>0.620189</td>\n",
       "      <td>0.335843</td>\n",
       "      <td>0.718491</td>\n",
       "      <td>0.530085</td>\n",
       "      <td>0.718491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>6.551815</td>\n",
       "      <td>1.267768</td>\n",
       "      <td>13.081332</td>\n",
       "      <td>1.293916</td>\n",
       "      <td>13.351133</td>\n",
       "      <td>1.307462</td>\n",
       "      <td>13.490909</td>\n",
       "      <td>0.096913</td>\n",
       "      <td>1.045597</td>\n",
       "      <td>0.096913</td>\n",
       "      <td>1.127576</td>\n",
       "      <td>0.697278</td>\n",
       "      <td>1.153274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.001930</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.055946</td>\n",
       "      <td>1.314213</td>\n",
       "      <td>0.086921</td>\n",
       "      <td>2.041856</td>\n",
       "      <td>0.094496</td>\n",
       "      <td>2.219795</td>\n",
       "      <td>0.050647</td>\n",
       "      <td>0.049257</td>\n",
       "      <td>0.052681</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.059534</td>\n",
       "      <td>0.069983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>2.552520</td>\n",
       "      <td>0.138812</td>\n",
       "      <td>3.085582</td>\n",
       "      <td>0.240582</td>\n",
       "      <td>5.347799</td>\n",
       "      <td>0.249537</td>\n",
       "      <td>5.546843</td>\n",
       "      <td>0.086058</td>\n",
       "      <td>0.114831</td>\n",
       "      <td>0.117948</td>\n",
       "      <td>0.156748</td>\n",
       "      <td>0.160511</td>\n",
       "      <td>0.156748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.030570</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.937334</td>\n",
       "      <td>6.558113</td>\n",
       "      <td>1.265994</td>\n",
       "      <td>8.857599</td>\n",
       "      <td>1.272536</td>\n",
       "      <td>8.903367</td>\n",
       "      <td>0.861933</td>\n",
       "      <td>0.732641</td>\n",
       "      <td>1.041766</td>\n",
       "      <td>0.732641</td>\n",
       "      <td>1.099458</td>\n",
       "      <td>0.840018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  SibSp  Parch      Fare  Embarked_me_cv  \\\n",
       "PassengerId                                                         \n",
       "206               3   2.0      0      1   10.4625        0.329050   \n",
       "119               1  24.0      0      1  247.5208        0.547759   \n",
       "705               3  26.0      1      0    7.8542        0.329050   \n",
       "403               3  21.0      1      0    9.8250        0.329050   \n",
       "115               3  17.0      0      0   14.4583        0.547759   \n",
       "42                2  27.0      1      0   21.0000        0.329050   \n",
       "265               3   NaN      0      0    7.7500        0.356709   \n",
       "73                2  21.0      0      0   73.5000        0.329050   \n",
       "74                3  26.0      1      0   14.4542        0.547759   \n",
       "309               2  30.0      1      0   24.0000        0.547759   \n",
       "703               3  18.0      0      1   14.4542        0.547759   \n",
       "101               3  28.0      0      0    7.8958        0.329050   \n",
       "868               1  31.0      0      0   50.4958        0.329050   \n",
       "853               3   9.0      1      1   15.2458        0.547759   \n",
       "\n",
       "             Cabin1_me_cv  Sex_me_cv  5NN_Class0  5NN_Class1  7NN_Class0  \\\n",
       "PassengerId                                                                \n",
       "206              0.500000   0.734677         0.0         1.0    0.000000   \n",
       "119              0.734801   0.186343         0.6         0.4    0.428571   \n",
       "705                   NaN   0.186343         0.6         0.4    0.714286   \n",
       "403                   NaN   0.734677         0.4         0.6    0.571429   \n",
       "115                   NaN   0.734677         0.2         0.8    0.142857   \n",
       "42                    NaN   0.734677         0.4         0.6    0.428571   \n",
       "265                   NaN   0.734677         0.4         0.6    0.285714   \n",
       "73                    NaN   0.186343         0.4         0.6    0.428571   \n",
       "74                    NaN   0.186343         0.6         0.4    0.714286   \n",
       "309                   NaN   0.186343         0.6         0.4    0.571429   \n",
       "703                   NaN   0.734677         0.2         0.8    0.142857   \n",
       "101                   NaN   0.734677         0.6         0.4    0.571429   \n",
       "868              0.507576   0.186343         0.6         0.4    0.571429   \n",
       "853                   NaN   0.734677         0.2         0.8    0.428571   \n",
       "\n",
       "             7NN_Class1  9NN_Class0  9NN_Class1  Same_Label_Streak  \\\n",
       "PassengerId                                                          \n",
       "206            1.000000    0.000000    1.000000                9.0   \n",
       "119            0.571429    0.444444    0.555556                2.0   \n",
       "705            0.285714    0.777778    0.222222                1.0   \n",
       "403            0.428571    0.666667    0.333333                1.0   \n",
       "115            0.857143    0.111111    0.888889                4.0   \n",
       "42             0.571429    0.555556    0.444444                2.0   \n",
       "265            0.714286    0.222222    0.777778                1.0   \n",
       "73             0.571429    0.555556    0.444444                1.0   \n",
       "74             0.285714    0.777778    0.222222                3.0   \n",
       "309            0.428571    0.666667    0.333333                3.0   \n",
       "703            0.857143    0.222222    0.777778                1.0   \n",
       "101            0.428571    0.555556    0.444444                1.0   \n",
       "868            0.428571    0.666667    0.333333                2.0   \n",
       "853            0.571429    0.444444    0.555556                1.0   \n",
       "\n",
       "             Norm_Class0_Min_Dist  Norm_Class1_Min_Dist  Dist_to_Neighbor_5  \\\n",
       "PassengerId                                                                   \n",
       "206                    999.000000              0.999986            0.571831   \n",
       "119                      0.999999              1.608924            2.516572   \n",
       "705                      6.410277              0.999909            0.112269   \n",
       "403                      1.110619              0.999989            0.157793   \n",
       "115                      4.067631              0.999986            0.288768   \n",
       "42                       0.999987              1.189989            0.106954   \n",
       "265                      1.003091              0.999989            0.190531   \n",
       "73                       0.999995              1.531288            0.387003   \n",
       "74                       0.999985             11.585759            0.814757   \n",
       "309                      0.999988              7.295723            0.634462   \n",
       "703                      0.999990              6.551815            1.267768   \n",
       "101                      1.001930              0.999977            0.055946   \n",
       "868                      0.999978              2.552520            0.138812   \n",
       "853                      6.030570              0.999993            0.937334   \n",
       "\n",
       "             Norm_Dist_to_Neighbor_5  Dist_to_Neighbor_7  \\\n",
       "PassengerId                                                \n",
       "206                         8.182631            0.856144   \n",
       "119                         1.890405            2.675798   \n",
       "705                        10.236291            0.151144   \n",
       "403                         1.666515            0.165482   \n",
       "115                         4.067631            0.416033   \n",
       "42                          1.438413            0.135873   \n",
       "265                         2.034240            0.198737   \n",
       "73                          1.828168            0.428944   \n",
       "74                         12.006565            0.913874   \n",
       "309                         7.639436            0.916857   \n",
       "703                        13.081332            1.293916   \n",
       "101                         1.314213            0.086921   \n",
       "868                         3.085582            0.240582   \n",
       "853                         6.558113            1.265994   \n",
       "\n",
       "             Norm_Dist_to_Neighbor_7  Dist_to_Neighbor_9  \\\n",
       "PassengerId                                                \n",
       "206                        12.251021            0.938202   \n",
       "119                         2.010013            2.895941   \n",
       "705                        13.780823            0.171489   \n",
       "403                         1.747722            0.217171   \n",
       "115                         5.860297            0.812020   \n",
       "42                          1.827339            0.234367   \n",
       "265                         2.121849            0.406510   \n",
       "73                          2.026293            0.504325   \n",
       "74                         13.467200            0.920443   \n",
       "309                        11.039704            0.920235   \n",
       "703                        13.351133            1.307462   \n",
       "101                         2.041856            0.094496   \n",
       "868                         5.347799            0.249537   \n",
       "853                         8.857599            1.272536   \n",
       "\n",
       "             Norm_Dist_to_Neighbor_9  5NN_Class0_Mean_Dist  \\\n",
       "PassengerId                                                  \n",
       "206                        13.425234            999.000000   \n",
       "119                         2.175380              1.750444   \n",
       "705                        15.635731              0.076433   \n",
       "403                         2.293628              0.131476   \n",
       "115                        11.438222              0.288768   \n",
       "42                          3.151968              0.077151   \n",
       "265                         4.340176              0.132497   \n",
       "73                          2.382388              0.272547   \n",
       "74                         13.564002              0.212158   \n",
       "309                        11.080384              0.142172   \n",
       "703                        13.490909              0.096913   \n",
       "101                         2.219795              0.050647   \n",
       "868                         5.546843              0.086058   \n",
       "853                         8.903367              0.861933   \n",
       "\n",
       "             5NN_Class1_Mean_Dist  7NN_Class0_Mean_Dist  7NN_Class1_Mean_Dist  \\\n",
       "PassengerId                                                                     \n",
       "206                      0.325906            999.000000              0.476230   \n",
       "119                      2.329213              1.750444              2.481582   \n",
       "705                      0.061618              0.099130              0.061618   \n",
       "403                      0.123961              0.148105              0.123961   \n",
       "115                      0.168231              0.288768              0.236508   \n",
       "42                       0.099925              0.096725              0.107183   \n",
       "265                      0.145633              0.132497              0.166874   \n",
       "73                       0.345105              0.319658              0.366065   \n",
       "74                       0.800478              0.492228              0.800478   \n",
       "309                      0.620189              0.335843              0.718491   \n",
       "703                      1.045597              0.096913              1.127576   \n",
       "101                      0.049257              0.052681              0.061812   \n",
       "868                      0.114831              0.117948              0.156748   \n",
       "853                      0.732641              1.041766              0.732641   \n",
       "\n",
       "             9NN_Class0_Mean_Dist  9NN_Class1_Mean_Dist  \n",
       "PassengerId                                              \n",
       "206                    999.000000              0.575909  \n",
       "119                      2.026409              2.564454  \n",
       "705                      0.118353              0.061618  \n",
       "403                      0.170621              0.123961  \n",
       "115                      0.288768              0.360062  \n",
       "42                       0.134107              0.107183  \n",
       "265                      0.132497              0.205660  \n",
       "73                       0.384879              0.366065  \n",
       "74                       0.614557              0.800478  \n",
       "309                      0.530085              0.718491  \n",
       "703                      0.697278              1.153274  \n",
       "101                      0.059534              0.069983  \n",
       "868                      0.160511              0.156748  \n",
       "853                      1.099458              0.840018  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_me_cv</th>\n",
       "      <th>Cabin1_me_cv</th>\n",
       "      <th>Sex_me_cv</th>\n",
       "      <th>5NN_Class0</th>\n",
       "      <th>5NN_Class1</th>\n",
       "      <th>7NN_Class0</th>\n",
       "      <th>7NN_Class1</th>\n",
       "      <th>9NN_Class0</th>\n",
       "      <th>9NN_Class1</th>\n",
       "      <th>Same_Label_Streak</th>\n",
       "      <th>Norm_Class0_Min_Dist</th>\n",
       "      <th>Norm_Class1_Min_Dist</th>\n",
       "      <th>Dist_to_Neighbor_5</th>\n",
       "      <th>Norm_Dist_to_Neighbor_5</th>\n",
       "      <th>Dist_to_Neighbor_7</th>\n",
       "      <th>Norm_Dist_to_Neighbor_7</th>\n",
       "      <th>Dist_to_Neighbor_9</th>\n",
       "      <th>Norm_Dist_to_Neighbor_9</th>\n",
       "      <th>5NN_Class0_Mean_Dist</th>\n",
       "      <th>5NN_Class1_Mean_Dist</th>\n",
       "      <th>7NN_Class0_Mean_Dist</th>\n",
       "      <th>7NN_Class1_Mean_Dist</th>\n",
       "      <th>9NN_Class0_Mean_Dist</th>\n",
       "      <th>9NN_Class1_Mean_Dist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.015943</td>\n",
       "      <td>1.467572</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>1.566420</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>1.634879</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>1.389339</td>\n",
       "      <td>0.065974</td>\n",
       "      <td>1.434958</td>\n",
       "      <td>0.073440</td>\n",
       "      <td>1.597338</td>\n",
       "      <td>0.073440</td>\n",
       "      <td>1.597338</td>\n",
       "      <td>0.055054</td>\n",
       "      <td>0.064576</td>\n",
       "      <td>0.059204</td>\n",
       "      <td>0.066792</td>\n",
       "      <td>0.059204</td>\n",
       "      <td>0.069008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.067858</td>\n",
       "      <td>1.568446</td>\n",
       "      <td>0.090979</td>\n",
       "      <td>2.102843</td>\n",
       "      <td>0.090979</td>\n",
       "      <td>2.102844</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>0.043264</td>\n",
       "      <td>0.063712</td>\n",
       "      <td>0.043264</td>\n",
       "      <td>0.070529</td>\n",
       "      <td>0.043264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>0.730681</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.095729</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.042149</td>\n",
       "      <td>3.524292</td>\n",
       "      <td>0.078934</td>\n",
       "      <td>6.600118</td>\n",
       "      <td>0.079865</td>\n",
       "      <td>6.677977</td>\n",
       "      <td>0.038754</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>0.050216</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>0.058554</td>\n",
       "      <td>0.011958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>1.015145</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>1.025234</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>1.094765</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>1.568451</td>\n",
       "      <td>0.109475</td>\n",
       "      <td>1.574424</td>\n",
       "      <td>0.138302</td>\n",
       "      <td>1.989004</td>\n",
       "      <td>0.151244</td>\n",
       "      <td>2.175137</td>\n",
       "      <td>0.082531</td>\n",
       "      <td>0.109267</td>\n",
       "      <td>0.103789</td>\n",
       "      <td>0.109267</td>\n",
       "      <td>0.109617</td>\n",
       "      <td>0.123259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>1.001900</td>\n",
       "      <td>0.076685</td>\n",
       "      <td>1.008142</td>\n",
       "      <td>0.082531</td>\n",
       "      <td>1.085003</td>\n",
       "      <td>0.076122</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.076215</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.077035</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>133.6500</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.117574</td>\n",
       "      <td>1.324097</td>\n",
       "      <td>1.200844</td>\n",
       "      <td>1.568457</td>\n",
       "      <td>1.422458</td>\n",
       "      <td>1.720706</td>\n",
       "      <td>1.560534</td>\n",
       "      <td>1.184685</td>\n",
       "      <td>1.232280</td>\n",
       "      <td>1.282032</td>\n",
       "      <td>1.232280</td>\n",
       "      <td>1.335342</td>\n",
       "      <td>1.476493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>1.001219</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>1.023659</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>1.023659</td>\n",
       "      <td>0.010871</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>153.4625</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>0.530683</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.640141</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.288510</td>\n",
       "      <td>1.343491</td>\n",
       "      <td>1.573020</td>\n",
       "      <td>1.640141</td>\n",
       "      <td>1.678422</td>\n",
       "      <td>1.750040</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.177095</td>\n",
       "      <td>1.573018</td>\n",
       "      <td>1.224983</td>\n",
       "      <td>1.603908</td>\n",
       "      <td>1.289760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>1.952409</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>1.952409</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>1.952409</td>\n",
       "      <td>0.027775</td>\n",
       "      <td>2.472611</td>\n",
       "      <td>0.018766</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>0.020684</td>\n",
       "      <td>0.021932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>1.675766</td>\n",
       "      <td>0.212009</td>\n",
       "      <td>1.675766</td>\n",
       "      <td>0.216147</td>\n",
       "      <td>1.708472</td>\n",
       "      <td>0.280948</td>\n",
       "      <td>2.220670</td>\n",
       "      <td>0.173649</td>\n",
       "      <td>0.212009</td>\n",
       "      <td>0.173649</td>\n",
       "      <td>0.214768</td>\n",
       "      <td>0.205188</td>\n",
       "      <td>0.214768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.9792</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>0.734801</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.705063</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.209640</td>\n",
       "      <td>2.470344</td>\n",
       "      <td>1.279039</td>\n",
       "      <td>2.612071</td>\n",
       "      <td>1.286998</td>\n",
       "      <td>2.628326</td>\n",
       "      <td>0.834908</td>\n",
       "      <td>0.948014</td>\n",
       "      <td>0.834908</td>\n",
       "      <td>1.056360</td>\n",
       "      <td>0.834908</td>\n",
       "      <td>1.113800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>1.015145</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>1.025234</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>1.094765</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.011110</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.356709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.112769</td>\n",
       "      <td>4.073365</td>\n",
       "      <td>0.112913</td>\n",
       "      <td>4.078558</td>\n",
       "      <td>0.112913</td>\n",
       "      <td>4.078558</td>\n",
       "      <td>0.044701</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.064174</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.075005</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.7875</td>\n",
       "      <td>0.547759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186343</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>1.502280</td>\n",
       "      <td>0.194443</td>\n",
       "      <td>1.682271</td>\n",
       "      <td>0.213285</td>\n",
       "      <td>1.845292</td>\n",
       "      <td>0.224425</td>\n",
       "      <td>1.941676</td>\n",
       "      <td>0.153360</td>\n",
       "      <td>0.173638</td>\n",
       "      <td>0.170276</td>\n",
       "      <td>0.173638</td>\n",
       "      <td>0.183051</td>\n",
       "      <td>0.173638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0.329050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>29.162276</td>\n",
       "      <td>2.165390</td>\n",
       "      <td>24.904674</td>\n",
       "      <td>2.531176</td>\n",
       "      <td>29.111662</td>\n",
       "      <td>2.699694</td>\n",
       "      <td>31.049829</td>\n",
       "      <td>1.251961</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.614246</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.614246</td>\n",
       "      <td>2.617634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  SibSp  Parch      Fare  Embarked_me_cv  \\\n",
       "PassengerId                                                         \n",
       "822               3  27.0      0      0    8.6625        0.329050   \n",
       "459               2  50.0      0      0   10.5000        0.329050   \n",
       "554               3  22.0      0      0    7.2250        0.547759   \n",
       "513               1  36.0      0      0   26.2875        0.329050   \n",
       "392               3  21.0      0      0    7.7958        0.329050   \n",
       "631               1  80.0      0      0   30.0000        0.329050   \n",
       "108               3   NaN      0      0    7.7750        0.329050   \n",
       "661               1  50.0      2      0  133.6500        0.329050   \n",
       "580               3  32.0      0      0    7.9250        0.329050   \n",
       "269               1  58.0      0      1  153.4625        0.329050   \n",
       "82                3  29.0      0      0    9.5000        0.329050   \n",
       "693               3   NaN      0      0   56.4958        0.329050   \n",
       "524               1  44.0      0      1   57.9792        0.547759   \n",
       "147               3  27.0      0      0    7.7958        0.329050   \n",
       "829               3   NaN      0      0    7.7500        0.356709   \n",
       "208               3  26.0      0      0   18.7875        0.547759   \n",
       "26                3  38.0      1      5   31.3875        0.329050   \n",
       "\n",
       "             Cabin1_me_cv  Sex_me_cv  5NN_Class0  5NN_Class1  7NN_Class0  \\\n",
       "PassengerId                                                                \n",
       "822                   NaN   0.186343         1.0         0.0    1.000000   \n",
       "459                   NaN   0.734677         0.4         0.6    0.428571   \n",
       "554                   NaN   0.186343         0.8         0.2    0.857143   \n",
       "513              0.730681   0.186343         0.6         0.4    0.714286   \n",
       "392                   NaN   0.186343         1.0         0.0    1.000000   \n",
       "631              0.507576   0.186343         0.6         0.4    0.714286   \n",
       "108                   NaN   0.186343         1.0         0.0    1.000000   \n",
       "661                   NaN   0.186343         0.8         0.2    0.857143   \n",
       "580                   NaN   0.186343         1.0         0.0    1.000000   \n",
       "269              0.530683   0.734677         0.0         1.0    0.142857   \n",
       "82                    NaN   0.186343         1.0         0.0    0.857143   \n",
       "693                   NaN   0.186343         0.8         0.2    0.571429   \n",
       "524              0.734801   0.734677         0.2         0.8    0.142857   \n",
       "147                   NaN   0.186343         1.0         0.0    1.000000   \n",
       "829                   NaN   0.186343         1.0         0.0    1.000000   \n",
       "208                   NaN   0.186343         0.8         0.2    0.857143   \n",
       "26                    NaN   0.734677         1.0         0.0    1.000000   \n",
       "\n",
       "             7NN_Class1  9NN_Class0  9NN_Class1  Same_Label_Streak  \\\n",
       "PassengerId                                                          \n",
       "822            0.000000    1.000000    0.000000                9.0   \n",
       "459            0.571429    0.333333    0.666667                1.0   \n",
       "554            0.142857    0.888889    0.111111                1.0   \n",
       "513            0.285714    0.777778    0.222222                2.0   \n",
       "392            0.000000    1.000000    0.000000                9.0   \n",
       "631            0.285714    0.666667    0.333333                3.0   \n",
       "108            0.000000    1.000000    0.000000                9.0   \n",
       "661            0.142857    0.777778    0.222222                3.0   \n",
       "580            0.000000    1.000000    0.000000                9.0   \n",
       "269            0.857143    0.222222    0.777778                6.0   \n",
       "82             0.142857    0.888889    0.111111                5.0   \n",
       "693            0.428571    0.666667    0.333333                4.0   \n",
       "524            0.857143    0.111111    0.888889                1.0   \n",
       "147            0.000000    1.000000    0.000000                9.0   \n",
       "829            0.000000    1.000000    0.000000                9.0   \n",
       "208            0.142857    0.888889    0.111111                2.0   \n",
       "26             0.000000    0.777778    0.222222                7.0   \n",
       "\n",
       "             Norm_Class0_Min_Dist  Norm_Class1_Min_Dist  Dist_to_Neighbor_5  \\\n",
       "PassengerId                                                                   \n",
       "822                      0.999908            999.000000            0.015943   \n",
       "459                      0.999978              1.389339            0.065974   \n",
       "554                      0.999977              0.999979            0.067858   \n",
       "513                      3.095729              0.999916            0.042149   \n",
       "392                      0.999908            999.000000            0.011028   \n",
       "631                      0.999986              1.568451            0.109475   \n",
       "108                      0.999987            999.000000            0.076210   \n",
       "661                      0.999999              1.117574            1.324097   \n",
       "580                      0.999908            999.000000            0.010877   \n",
       "269                      1.640141              0.999999            1.288510   \n",
       "82                       0.999911              1.952409            0.021932   \n",
       "693                      0.999992              1.675766            0.212009   \n",
       "524                      1.705063              0.999998            1.209640   \n",
       "147                      0.999908            999.000000            0.011028   \n",
       "829                      0.999964            999.000000            0.112769   \n",
       "208                      0.999991              1.502280            0.194443   \n",
       "26                       0.999988             29.162276            2.165390   \n",
       "\n",
       "             Norm_Dist_to_Neighbor_5  Dist_to_Neighbor_7  \\\n",
       "PassengerId                                                \n",
       "822                         1.467572            0.017017   \n",
       "459                         1.434958            0.073440   \n",
       "554                         1.568446            0.090979   \n",
       "513                         3.524292            0.078934   \n",
       "392                         1.015145            0.011138   \n",
       "631                         1.574424            0.138302   \n",
       "108                         1.001900            0.076685   \n",
       "661                         1.200844            1.568457   \n",
       "580                         1.001219            0.011120   \n",
       "269                         1.343491            1.573020   \n",
       "82                          1.952409            0.021932   \n",
       "693                         1.675766            0.216147   \n",
       "524                         2.470344            1.279039   \n",
       "147                         1.015145            0.011138   \n",
       "829                         4.073365            0.112913   \n",
       "208                         1.682271            0.213285   \n",
       "26                         24.904674            2.531176   \n",
       "\n",
       "             Norm_Dist_to_Neighbor_7  Dist_to_Neighbor_9  \\\n",
       "PassengerId                                                \n",
       "822                         1.566420            0.017760   \n",
       "459                         1.597338            0.073440   \n",
       "554                         2.102843            0.090979   \n",
       "513                         6.600118            0.079865   \n",
       "392                         1.025234            0.011893   \n",
       "631                         1.989004            0.151244   \n",
       "108                         1.008142            0.082531   \n",
       "661                         1.422458            1.720706   \n",
       "580                         1.023659            0.011120   \n",
       "269                         1.640141            1.678422   \n",
       "82                          1.952409            0.027775   \n",
       "693                         1.708472            0.280948   \n",
       "524                         2.612071            1.286998   \n",
       "147                         1.025234            0.011893   \n",
       "829                         4.078558            0.112913   \n",
       "208                         1.845292            0.224425   \n",
       "26                         29.111662            2.699694   \n",
       "\n",
       "             Norm_Dist_to_Neighbor_9  5NN_Class0_Mean_Dist  \\\n",
       "PassengerId                                                  \n",
       "822                         1.634879              0.013623   \n",
       "459                         1.597338              0.055054   \n",
       "554                         2.102844              0.055561   \n",
       "513                         6.677977              0.038754   \n",
       "392                         1.094765              0.010958   \n",
       "631                         2.175137              0.082531   \n",
       "108                         1.085003              0.076122   \n",
       "661                         1.560534              1.184685   \n",
       "580                         1.023659              0.010871   \n",
       "269                         1.750040            999.000000   \n",
       "82                          2.472611              0.018766   \n",
       "693                         2.220670              0.173649   \n",
       "524                         2.628326              0.834908   \n",
       "147                         1.094765              0.010958   \n",
       "829                         4.078558              0.044701   \n",
       "208                         1.941676              0.153360   \n",
       "26                         31.049829              1.251961   \n",
       "\n",
       "             5NN_Class1_Mean_Dist  7NN_Class0_Mean_Dist  7NN_Class1_Mean_Dist  \\\n",
       "PassengerId                                                                     \n",
       "822                    999.000000              0.014439            999.000000   \n",
       "459                      0.064576              0.059204              0.066792   \n",
       "554                      0.043264              0.063712              0.043264   \n",
       "513                      0.011958              0.050216              0.011958   \n",
       "392                    999.000000              0.010994            999.000000   \n",
       "631                      0.109267              0.103789              0.109267   \n",
       "108                    999.000000              0.076215            999.000000   \n",
       "661                      1.232280              1.282032              1.232280   \n",
       "580                    999.000000              0.010909            999.000000   \n",
       "269                      1.177095              1.573018              1.224983   \n",
       "82                     999.000000              0.019294              0.021932   \n",
       "693                      0.212009              0.173649              0.214768   \n",
       "524                      0.948014              0.834908              1.056360   \n",
       "147                    999.000000              0.010994            999.000000   \n",
       "829                    999.000000              0.064174            999.000000   \n",
       "208                      0.173638              0.170276              0.173638   \n",
       "26                     999.000000              1.614246            999.000000   \n",
       "\n",
       "             9NN_Class0_Mean_Dist  9NN_Class1_Mean_Dist  \n",
       "PassengerId                                              \n",
       "822                      0.015177            999.000000  \n",
       "459                      0.059204              0.069008  \n",
       "554                      0.070529              0.043264  \n",
       "513                      0.058554              0.011958  \n",
       "392                      0.011110            999.000000  \n",
       "631                      0.109617              0.123259  \n",
       "108                      0.077035            999.000000  \n",
       "661                      1.335342              1.476493  \n",
       "580                      0.010956            999.000000  \n",
       "269                      1.603908              1.289760  \n",
       "82                       0.020684              0.021932  \n",
       "693                      0.205188              0.214768  \n",
       "524                      0.834908              1.113800  \n",
       "147                      0.011110            999.000000  \n",
       "829                      0.075005            999.000000  \n",
       "208                      0.183051              0.173638  \n",
       "26                       1.614246              2.617634  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooster = random_tree.best_estimator_.get_booster()\n",
    "model_bytearray = mybooster.save_raw()[4:]\n",
    "def myfun(self=None):\n",
    "    return model_bytearray\n",
    "\n",
    "mybooster.save_raw = myfun\n",
    "\n",
    "import shap\n",
    "# explainer = shap.TreeExplainer(mybooster, X_train_final)\n",
    "# shap_values = explainer.shap_values(X_val_final)\n",
    "\n",
    "# # Look into Mr. Lee Ling ID_170\n",
    "# Lee_loc = y_val.index.get_loc(170)\n",
    "# shap.initjs() #initialize javascript in cell\n",
    "# shap.force_plot(explainer.expected_value, shap_values[Lee_loc], X_val[Lee_loc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 look at tree's feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 from tree purity reduction perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm_Class0_Min_Dist \t\t 0.72277766\n",
      "Norm_Class1_Min_Dist \t\t 0.21292743\n",
      "5NN_Class0 \t\t 0.016827315\n",
      "7NN_Class0 \t\t 0.013498162\n",
      "Age \t\t 0.008724501\n",
      "5NN_Class1_Mean_Dist \t\t 0.008447513\n",
      "Cabin1_me_cv \t\t 0.0070667574\n",
      "Pclass \t\t 0.0054575056\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine feature importance\n",
    "top_n = 8\n",
    "\n",
    "top_importance = np.sort(random_tree.best_estimator_.feature_importances_)[::-1][:top_n]\n",
    "top_indices = np.argsort(random_tree.best_estimator_.feature_importances_)[::-1][:top_n]\n",
    "top_feats = np.array(X_val_final.columns)[top_indices]\n",
    "\n",
    "for feat, imp in zip(top_feats, top_importance):\n",
    "    print(feat, '\\t\\t', imp)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip 1: KNN feature is leaking the label to the model big-time (Class0_Min_Dist, Class1_Min_Dist)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.2 SHAP summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-2bf55cfd84cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#A summary plot with the shapley value (feature importance)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'shap_values' is not defined"
     ]
    }
   ],
   "source": [
    "#A summary plot with the shapley value (feature importance) \n",
    "shap.summary_plot(shap_values, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = random_tree.best_estimator_.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_output = pd.Series(y_test_hat, index=test.index, name = 'Survived')\n",
    "pd.DataFrame(y_test_output).to_csv('Titanic_4_feat_gen_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apparently the model doesn't work due to knn features drastically overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
